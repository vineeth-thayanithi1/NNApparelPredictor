{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1 ( Please Restart kernel before Executing Each Task)\n",
    "import numpy as np\n",
    "import random\n",
    "import mnist_reader\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from itertools import zip_longest\n",
    "#logistic function \n",
    "def sig(z):\n",
    "    sig= 1/(1+np.exp(-z))\n",
    "    return sig\n",
    "#sigmoid derivative \n",
    "def sig_del(a):\n",
    "    return a*(1-a)\n",
    "#softmax\n",
    "def softm(x):\n",
    "    \n",
    "    expx = np.exp(x-np.max(x))\n",
    "    return expx / expx.sum(axis = 1, keepdims = True)\n",
    "#loss function \n",
    "def loss(a,y):\n",
    "    return np.sum(-np.log(a[range(y.shape[0]),y]))/y.shape[0]\n",
    "#import \n",
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "X_train_norm=X_train/255\n",
    "X_test_norm=X_test/255\n",
    "x1= X_train_norm\n",
    "y1= y_train\n",
    "epochs=500\n",
    "learning_rate= 0.5\n",
    "#one hot     \n",
    "onehot_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "y2 = y_train.reshape(len(y_train), 1)\n",
    "y2 = onehot_encoder.fit_transform(y2)\n",
    "#print(y2)\n",
    "    \n",
    "m=y1.shape[0]\n",
    "hidden_nodes=64\n",
    "#weight initialization \n",
    "weights1 = np.random.randn(x1.T.shape[0],hidden_nodes) \n",
    "weights2 = np.random.randn(hidden_nodes,10) \n",
    "bias1=np.zeros(hidden_nodes)\n",
    "bias2=np.zeros(10)\n",
    "    \n",
    "l3=[]\n",
    "    #print(x1.shape)\n",
    "    #print(weights1.shape)\n",
    "    #print(weights2.shape)\n",
    "   \n",
    "    \n",
    "for epoch in range(epochs):\n",
    "        #foward propogation\n",
    "    z1= np.matmul(x1,weights1)+ bias1\n",
    "    a1= sig(z1)\n",
    "        #print(a1.shape)\n",
    "\n",
    "    z2= np.matmul(a1,weights2)+ bias2\n",
    "    a2= softm(z2)\n",
    "    #print(a2.shape)\n",
    "    \n",
    "    final_loss= loss(a2,y1)\n",
    "    print(\"Loss\",epoch,\":\",final_loss)\n",
    "    l3.append(final_loss)\n",
    "    \n",
    "    #backprop\n",
    "    del_z2 = a2 - y2\n",
    "    #print(dz2.shape)\n",
    "    del_weights2 = (1/m) * np.dot(a1.T, del_z2)\n",
    "    del_bias2 = (1/m) * np.sum(del_z2,axis = 0, keepdims = True)\n",
    "   \n",
    "    del_a1 = np.dot(del_z2, weights2.T)\n",
    "    del_z1 = del_a1 * sig_del(a1)\n",
    "    del_weights1 = (1/m) * np.dot(x1.T,del_z1)\n",
    "    del_bias1 = (1/m) * np.sum(del_z1,axis = 0, keepdims = True)\n",
    "    \n",
    "    \n",
    "    weights1 = weights1 - learning_rate*del_weights1\n",
    "    bias1 = bias1 - learning_rate*del_bias1\n",
    "    weights2 = weights2 - learning_rate*del_weights2\n",
    "    bias2 = bias2 - learning_rate*del_bias2\n",
    "#prediction\n",
    "temp_acc=0\n",
    "y_pred=[]\n",
    "for i,j in zip_longest(X_test_norm, y_test):\n",
    "    z1 = np.dot(i, weights1) + bias1\n",
    "    a1 = sig(z1)            \n",
    "    z2 = np.dot(a1, weights2) + bias2\n",
    "    a2 = softm(z2)\n",
    "    predicted=np.argmax(a2)\n",
    "    y_pred.append(predicted)\n",
    "    if predicted == j:\n",
    "        temp_acc= temp_acc+1\n",
    "accuracy=(temp_acc/X_test_norm.shape[0])*100\n",
    "print(\"Test Accuracy:\", accuracy,\"%\")\n",
    "\n",
    "#confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1 Graph \n",
    "plt.figure(1)  \n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import SGD\n",
    "import keras.losses\n",
    "import keras.utils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import numpy as np \n",
    "import mnist_reader\n",
    "#import and normalization\n",
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "X_test_norm= X_test/255\n",
    "X_train_norm= X_train/255\n",
    "#one hot\n",
    "y1= keras.utils.to_categorical(y_train)\n",
    "#Model \n",
    "model = Sequential([Dense(784),Dense(128, activation=tf.nn.sigmoid), Dense(10, activation=tf.nn.softmax)])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\",metrics=['accuracy'])\n",
    "#model train\n",
    "model.fit(X_train_norm,y1,epochs=40,validation_split=0.1)\n",
    "#model eval\n",
    "loss, accuracy = model.evaluate(X_test_norm,keras.utils.to_categorical(y_test))\n",
    "#model predict \n",
    "y_pred=model.predict_classes(X_test_norm)\n",
    "#confusion Matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",accuracy*100)\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Activation,Conv2D\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import SGD\n",
    "import keras.losses\n",
    "import keras.utils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np \n",
    "import mnist_reader\n",
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "X_train1=(np.reshape(X_train,(60000,28,28,1)))/255\n",
    "X_test1=(np.reshape(X_test,(10000,28,28,1)))/255\n",
    "y1= keras.utils.to_categorical(y_train)\n",
    "#convolutional model \n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#train \n",
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train1, y1, epochs=5, validation_split=0.1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test1, keras.utils.to_categorical( y_test))\n",
    "\n",
    "y_pred=model.predict_classes(X_test1)\n",
    "\n",
    "print(\"Accuracy:\",test_accuracy*100)\n",
    "\n",
    "#confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
